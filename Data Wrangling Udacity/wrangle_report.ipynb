{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling Process\n",
    "\n",
    "![WeRateDogs](https://cdn.shopify.com/s/files/1/1352/9125/files/wrd_logo_website-200h_540x.png?v=1599580382)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Dataset\n",
    "\n",
    "## WeRateDogs\n",
    "\n",
    "### Delimited Data\n",
    "Weratedogs is a novelty Twitter account that rates images of dogs. I was provided a url for an archive of Tweet data stored in a CSV that was linked, a machine learning image predictor dataset as a linked tsv. I read both of these files from their url into Pandas dataframes.\n",
    "\n",
    "### Tweepy and Twitter\n",
    "\n",
    "In order to ensure data was accurate, I needed to pull each Tweet from the delimited data. Using `Tweepy`, I wrote multiple JSON objects to a file by calling the twitter API. Each line of the Tweet info was written into a nested list that was read into a DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessing Data\n",
    "\n",
    "### Visually\n",
    "\n",
    "Each dataset has forms of missing or inaccurate data. Reading a few lines you could see lots of NaN values. Categorical data like dog type was split across 4 different columns. Also, there were 3 datasets relating to potentially 1 observation.\n",
    "\n",
    "### Programaitcally assessing\n",
    "\n",
    "Using `df.info()`, `df.describe()` and some other dataframe items, I was able to see columns that had incorrect data types. For example, `tweet_id` was an integer in all the dataframes. Correcting this to a string symbolically related its value as a 'name' instead of a value and allowed easier calling of the Twitter API OMbed later on.\n",
    "\n",
    "The image dataframe and the tweet dataframe were also not the same size. This means that some tweets were gone or not parsed by the machine learning algorithm that made the image TSV file. \n",
    "\n",
    "Reading some values, I was able to document 2 tidiness issues upfront and 9 different cleaning issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning\n",
    "\n",
    "Using a variety of techniques, I corrected data types, values, joined tables. The attached Wrangle Act has further detail on what explicit steps were needed. A few libraries that were used to clean included the following:\n",
    "\n",
    "Pandas\n",
    "regex\n",
    "requests\n",
    "Tweepy\n",
    "Json\n",
    "\n",
    "A note before describing the methods below, I chose to clean the data before tidying the structure. Addressing the structure first would have sped the process up and shown fewer errors but may not have worked if a different set of tables would be joined in the future. Typically tidying the data first would be best practice if I knew the total scope of analysis before cleaning.\n",
    "\n",
    "### Issues and Methods\n",
    "\n",
    "#### Issue 1: tweet ID is an integer\n",
    "\n",
    "Using `astype.str()` I changed the type value of `tweet_id` in all 3 dataframes to a string. Since a tweet id is more like a name than a calculation, this datatype allowed it\n",
    "\n",
    "#### Issue 2: Timestamp not a datetime dtype\n",
    "\n",
    "Using `to_datetime()` method, converted this column in the dataframe to a proper descriptive type\n",
    "\n",
    "#### Issue 3: 181 retweets\n",
    "\n",
    "Using the `drop()` method, all retweets were removed. Since these were not sourced directly from WeRateDogs, they were removed.\n",
    "\n",
    "#### Issue 4: Invalid denominator in some rows. Each denominator needs to be 10, reduced to 10 or dropped.\n",
    "\n",
    "##### 4.1: Replace al denominators == 0\n",
    "\n",
    "Using `df.at()` I replaced the single 0 denominator to the correct value\n",
    "\n",
    "##### 4.2: Fix other non 10 denominators in table\n",
    "\n",
    "I created a list of indexes for rows denominators that were not 10. Viewing these rows, I manually reviewed some tweets which had no rating data and dropped them from the dataframe.\n",
    "\n",
    "Another index list was created and a numerator was iterated on to update to the appropriate values.\n",
    "\n",
    "Visually, I could see the remaining rows were all divisible by 10. I converted the index values to a list to iterate over. I iterated over these values finding the appropriate rating of n/10\n",
    "\n",
    "#### Issue 5: Invalid Dog Names\n",
    "\n",
    "Using str.lower() method I created a list of all rows that had a name that was not a proper noun. I added the name None to this list. I ran a loop to find if the `text` had a 'named' or 'name is'. I used these indexes in the string to populate names if I could find them and otherwise replace names with an empty string. Using pd.NaN might have been more appropriate but I was recieving an error that is documented in the code lines.\n",
    "\n",
    "#### Issue 6: Invalid Links from vine.co\n",
    "\n",
    "Vine is a service owned by Twitter that was shut down. There still exist a data archive but it only contains text, and users are able to delete their content. I removed every line that sourced vine.co to ensure the data that was being worked with was readily verifiable.\n",
    "\n",
    "\n",
    "#### Issue 7: Invalid numerator entries\n",
    "\n",
    "I used `df.describe()` on the `rating_numerator` column to get an overview of the makeup of this columns data. I noticed some strangeness and sought to address them with manual and programatic cleaning\n",
    "\n",
    "##### 7.1: Novelty Entries\n",
    "\n",
    "A few novelty entries slipped into the dataset and were removed using `drop()` individually, such as 666 and other pop-culture references. I then searched though a few subsets of data manually and removed many rows that were not dog ratings. \n",
    "\n",
    "##### 7.2: Decimal values in numerator instead of real values\n",
    "\n",
    "Once I found a majority of posts were dogs instead of other types of tweet at the rating 7 mark, I moved on to replacing ratings that had decimal values into rounded integers. For example, in the initial dataframe, a dog rated 11.27/10 was listed as 27/10. I looped through the entire dataframe looking for values that conformed to this regex `'\\d+\\.\\d\\d\\/10'`. I created a list of indexes of the rows that fit this mold that also contained the string value `[[index, regex]]`. Using `split('/')`, `int()` and `round()` I extracted the numerator as a rounded integer. I chose a a rounded integer as it followed the structure of the rest of the data. \n",
    "\n",
    "Again, looping through the index of the lines that met the regex expression, I applied the appropriate integer to numerator for that location\n",
    "\n",
    "#### Issue 8: Some columns may be renamed to improve clarity in df_image\n",
    "\n",
    "##### 8.1: `img_num` not descriptive\n",
    "\n",
    "In this section I reviewed what this column meant by assessing `value_counts()` and reviewing manually a few tweets to determine that it described the number of images attached to a tweet. I therefore renamed the column to `num_images`.\n",
    "\n",
    "##### 8.2: p1-p3_dog are not descriptive\n",
    "\n",
    "I used a description left by the creator of the files to rename these columns to help with understanding. In this section, I also opted to rename the `rating_numerator` to `rating_out_of_10` and drop `rating_denominator`. This allowed the dataset to maintain it's meanings but also lower it's overall size\n",
    "\n",
    "\n",
    "#### Issue 9: Dog breeds can be standardized\n",
    "\n",
    "In the `#_guess` columns, I used `str.lower()` to enforce a lowercase string on all dog breed strings. This would allow easier grouping.\n",
    "\n",
    "### Tidiness 1: Join all tables\n",
    "\n",
    "Using `pd.df.merge()` inner joins, the 3 datasets were combined, This created the overall smaller table mentioned in the note at the top. DOing this item first would have saved time with cleaning but maybe would have made future analysis more difficult if new tables were added.\n",
    "\n",
    "\n",
    "### Tidiness 2: Create a `type` column to store the doggo type\n",
    "\n",
    "The `doggo` type was stored across 4 columns. I created a new `type` column and iterated over the entire dataset to append the string of the 4 single type columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing Data:\n",
    "\n",
    "The new cleaned and combined dataframe was stored to the CSV specified in the instructions. This csv was then reloaded to a new dataframe set. WHile more memory intensive, this copy would ensure changes would not affect the source dataframe.\n",
    "\n",
    "One note is that `tweet_id` reverted to an integer when being converted to csv and I manually reset this the data type to string using `astype()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization\n",
    "Using matplotlib, I did some small visual analysis to determine the relationship between Charlie dog ratings and the mean. I also reviewed how strong the relationship between retweet and likes where in a linear regression model. Both of these are ploted in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook wrangle_report.ipynb to html\n",
      "[NbConvertApp] Writing 571485 bytes to wrangle_report.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.system('jupyter nbconvert --to html wrangle_report.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
